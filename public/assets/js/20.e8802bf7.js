(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{570:function(a,v,_){"use strict";_.r(v);var e=_(13),s=Object(e.a)({},(function(){var a=this,v=a.$createElement,_=a._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[_("h2",{attrs:{id:"集合"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#集合"}},[a._v("#")]),a._v(" 集合")]),a._v(" "),_("h3",{attrs:{id:"前言"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),_("p",[a._v("集合存放的都是对象，即引用数据类型，基础数据类型不能放到集合中。")]),a._v(" "),_("ul",[_("li",[_("p",[a._v("List，Set，Map都是接口，前两个继承至Collection接口，Map为独立接口")])]),a._v(" "),_("li",[_("p",[a._v("List下有ArrayList、Vector、LinkedList")])]),a._v(" "),_("li",[_("p",[a._v("Set下有HashSet、LinkedHashSet、TreeSet")])]),a._v(" "),_("li",[_("p",[a._v("Map下有Hashtable、LinkedHashMap、HashMap、TreeMap")])]),a._v(" "),_("li",[_("p",[a._v("Collection接口下还有个Queue接口，有PriorityQueue类。")])])]),a._v(" "),_("hr"),a._v(" "),_("h3",{attrs:{id:"list"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#list"}},[a._v("#")]),a._v(" List")]),a._v(" "),_("p",[a._v("ArrayList、Vector、LinkedList")]),a._v(" "),_("p",[a._v("特点：")]),a._v(" "),_("p",[a._v("无序、可重复、可null")]),a._v(" "),_("p",[a._v("ArrayList：线程不安全，增删改查快，数据结构是单向链表，初始化长度一般是10，扩容倍数是1.5")]),a._v(" "),_("p",[a._v("Vector：线程安全，但查询比ArrayList慢很多；可以设置增长因子，而ArrayList不可以。")]),a._v(" "),_("p",[a._v("LinkedList：线程不安全，增删改查快，双向链表，其他特性与ArrayList一致")]),a._v(" "),_("p",[a._v("==fail-fast机制==")]),a._v(" "),_("p",[a._v("在for中删除元素就会触发fail-fast避免被修改")]),a._v(" "),_("p",[a._v("==fail-save机制==")]),a._v(" "),_("p",[a._v("为避免fail-fast可使用fail-save集合类 fail-save的原理是不是直接在原有集合上操作而是将原有集合进行拷贝在拷贝上的集合进行增删改的操作，完成后将拷贝的集合引用到原集合上 使用了读写分离的思想")]),a._v(" "),_("hr"),a._v(" "),_("h3",{attrs:{id:"set"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#set"}},[a._v("#")]),a._v(" Set")]),a._v(" "),_("p",[a._v("HashSet、TreeSet、LinkedHashSet")]),a._v(" "),_("p",[a._v("特点：")]),a._v(" "),_("p",[a._v("无序、不可重复、可null")]),a._v(" "),_("p",[a._v("HashSet：在JDK1.7之前，基于哈希表实现，增删改查快；1.8之后是链表+二叉树，链表长度>8，将链表换成二叉树")]),a._v(" "),_("p",[a._v("TreeSet：基于红黑树实现，有排序功能，有序")]),a._v(" "),_("p",[a._v("排序：自然排序，比较器排序。可以自定义规则，默认是自然排序，按hashCode值升序插入")]),a._v(" "),_("p",[a._v("Compare(Obj o1, Obj o2);")]),a._v(" "),_("p",[a._v("LinkedHashSet：线程不安全，双向链表，但是有序")]),a._v(" "),_("h3",{attrs:{id:"map"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#map"}},[a._v("#")]),a._v(" Map")]),a._v(" "),_("p",[a._v("HashMap、TreeMap、LinkedHashMap、ConcurrentHashMap")]),a._v(" "),_("p",[a._v("特点：")]),a._v(" "),_("p",[a._v("数组，数组内部是一个链表；无序、key不可重复、重复插入value会被覆盖，key、value可null")]),a._v(" "),_("p",[a._v("HashMap：")]),a._v(" "),_("p",[a._v("1.数组的每个元素都是一个链表（或红黑树，当链表长度超过一定阈值时会转化为红黑树）的头节点")]),a._v(" "),_("p",[a._v("2.当 "),_("code",[a._v("HashMap")]),a._v(" 中的元素数量超过数组大小的一定比例（默认为0.75）时，"),_("code",[a._v("HashMap")]),a._v(" 会进行扩容。扩容操作会创建一个新的数组，其大小是原数组大小的两倍，然后将原数组中的元素重新哈希并插入到新数组中")]),a._v(" "),_("p",[a._v("3.如果链表长度超过一定的阈值（默认为8），链表会转化为红黑树，")]),a._v(" "),_("p",[a._v("哈希函数在HashMap中的作用")]),a._v(" "),_("p",[a._v("1.确定存储位置：用对应的hashCode%arraySize确定存储位置")]),a._v(" "),_("p",[a._v("2.快速查找：每个key都有对应的hash值。")]),a._v(" "),_("p",[a._v("3.碰撞处理：如果有重复，则用用开放寻址法处理，放到红黑树的最后一个")]),a._v(" "),_("p",[a._v("4.均匀分布：尽可能把不同的键映射到不同的索引上，并且减少碰撞的几率")]),a._v(" "),_("p",[a._v("TreeMap：基于红黑树实现，可以对键进行排序")]),a._v(" "),_("p",[a._v("LinkedHashMap：按照插入的顺序排序，双向链表")]),a._v(" "),_("p",[a._v("ConcurrentHashMap:")]),a._v(" "),_("p",[a._v("1.在JDK 1.8中，ConcurrentHashMap的实现方式进行了改进，使用分段锁（思想）和“CAS+Synchronized”的机制来保证线程安全。")]),a._v(" "),_("p",[a._v("2.如何保证fail-safe")]),a._v(" "),_("p",[a._v("在 JDK 1.8 中，ConcurrentHashMap 中的 Segment 被移除了，取而代之的是使用类似于cas+synchronized的机制来实现并发访问。在遍历 ConcurrentHashMap 时，只需要获取每个桶的头结点即可，因为每个桶的头结点是原子更新的，不会被其他线程修改。这个设计允许多个线程同时修改不同的桶，这减少了并发修改的概率，从而降低了冲突和数据不一致的可能性。")]),a._v(" "),_("p",[a._v("==HashMap与HashTable的区别==")]),a._v(" "),_("p",[a._v("1.HashMap线程不安全，HashTable线程安全")]),a._v(" "),_("p",[a._v("2.HashMap的初始容量默认为16，Hashtable的初始容量默认为11，两者的填充因子默认都是0.75。")]),a._v(" "),_("p",[a._v("3.HashMap和Hashtable的底层实现都是数组+链表结构，但它们计算hash的方式不同")]),a._v(" "),_("p",[a._v("4.HashMap允许null作为键或值，Hashtable不允许null作为键或值")]),a._v(" "),_("p",[a._v("==HashMap在并发插入中会出现什么问题==")]),a._v(" "),_("p",[a._v("1.会导致cpu占用短暂飙升")]),a._v(" "),_("p",[a._v("2.在put操作时会出现覆盖问题")]),a._v(" "),_("p",[a._v("3.HashMap在扩容的时候，会将元素插入链表头部")])])}),[],!1,null,null,null);v.default=s.exports}}]);